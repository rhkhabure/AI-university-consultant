{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afb9f24",
   "metadata": {},
   "source": [
    "# AI Consultant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5513426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adda3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ayt next im going to create a basic instance\n",
    "consultant_bot = ChatBot(\n",
    "    \"FacultyConsultant\",\n",
    "    storage_adapter=\"chatterbot.storage.SQLStorageAdapter\",\n",
    "    database_uri=\"sqlite:///consultant_db.sqlite3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd7f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here im trying to diversify the training data a bit more\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG'\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for name, score, grade in rows:\n",
    "    responses = [\n",
    "        f\"{name} has a mean score of {score} and a grade of {grade}.\",\n",
    "        f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\",\n",
    "        f\"The evaluation for {name} shows a mean score of {score} and grade {grade}.\"\n",
    "    ]\n",
    "    \n",
    "    questions = [\n",
    "        f\"What is the evaluation for {name}?\",\n",
    "        f\"Tell me about {name}.\",\n",
    "        f\"How did {name} perform?\",\n",
    "        f\"Evaluation for {name}?\"\n",
    "    ]\n",
    "    \n",
    "    for q in questions:\n",
    "        for r in responses:\n",
    "            trainer.train([q, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f9197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('faculty_evaluations',)]\n"
     ]
    }
   ],
   "source": [
    "# Just gotta confirm that the database has been created and tables exist\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb20621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok now that ik that lets move on\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG'\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "qa_pairs = []\n",
    "\n",
    "for name, score, grade in rows:\n",
    "    qa_pairs.append([\n",
    "        f\"What is the evaluation for {name}?\",\n",
    "        f\"{name} has a mean score of {score} and a grade of {grade}.\"\n",
    "    ])\n",
    "\n",
    "for conversation in qa_pairs:\n",
    "    trainer.train(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51287d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the evaluation for Afundi, Patrick Omuhinda?\n"
     ]
    }
   ],
   "source": [
    "# Ok lets test it out\n",
    "response = consultant_bot.get_response(\"What is the evaluation for Afundi, Patrick Omuhinda?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d5f79",
   "metadata": {},
   "source": [
    "ok the bot is alive and is giving out the defualt response so that great.Now the next step is to verify that it’s also pulling from the DB-trained Q&A pairs. Right now, it’s defaulting to the generic greeting because that’s the strongest match in its training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595172dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the evaluation for Afundi, Patrick Omuhinda?\n"
     ]
    }
   ],
   "source": [
    "response = consultant_bot.get_response(\"What is the evaluation for Afundi, Patrick Omuhinda?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01daadd",
   "metadata": {},
   "source": [
    "ok so I ran that code and got the following responses with each rerun, 'What can you do?','Hello','What is the evaluation for Afundi, Patrick Omuhinda?' just those three on loop\n",
    "Ok so its just looping thru some basic best match responses. So lets adjust things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a3176",
   "metadata": {},
   "source": [
    "so i made a change to the upper section using a threshold and i noticed that if there is a difference in spacing or phrasing or even typing the bot break down and that isnt good so lets fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7564b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here im trying to diversify the training data a bit more\n",
    "qa_pairs = []\n",
    "\n",
    "for name, score, grade in rows:\n",
    "    responses = [\n",
    "        f\"{name} has a mean score of {score} and a grade of {grade}.\",\n",
    "        f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\",\n",
    "        f\"The evaluation for {name} shows a mean score of {score} and grade {grade}.\"\n",
    "    ]\n",
    "    \n",
    "    questions = [\n",
    "        f\"What is the evaluation for {name}?\",\n",
    "        f\"Tell me about {name}.\",\n",
    "        f\"How did {name} perform?\",\n",
    "        f\"Evaluation for {name}?\"\n",
    "    ]\n",
    "    \n",
    "    for q in questions:\n",
    "        for r in responses:\n",
    "            trainer.train([q, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e465a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Afundi perform?\n"
     ]
    }
   ],
   "source": [
    "response = consultant_bot.get_response(\"How did Afundi perform?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268866a",
   "metadata": {},
   "source": [
    "so apperently ChatterBot sometimes echoes the input when confidence is low, which explains why we saw “How did Afundi perform?” as a response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c914f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also i want to adjust the thresholds for similarity matching\n",
    "consultant_bot = ChatBot(\n",
    "    \"FacultyConsultant\",\n",
    "    storage_adapter=\"chatterbot.storage.SQLStorageAdapter\",\n",
    "    database_uri=\"sqlite:///consultant_db.sqlite3\",\n",
    "    logic_adapters=[\n",
    "        {\n",
    "            \"import_path\": \"chatterbot.logic.BestMatch\",\n",
    "            \"default_response\": \"I can answer faculty evaluation questions if you ask about a specific instructor.\",\n",
    "            \"maximum_similarity_threshold\": 0.75\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8f62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets add more vairaitions for the responses\n",
    "for name, score, grade in rows:\n",
    "    questions = [\n",
    "        f\"What is the evaluation for {name}?\",\n",
    "        f\"Tell me about {name}.\",\n",
    "        f\"How did {name} perform?\",\n",
    "        f\"Evaluation for {name}?\",\n",
    "        f\"Performance of {name}?\"\n",
    "    ]\n",
    "    \n",
    "    responses = [\n",
    "        f\"{name} has a mean score of {score} and a grade of {grade}.\",\n",
    "        f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\",\n",
    "        f\"The evaluation for {name} shows a mean score of {score} and grade {grade}.\"\n",
    "    ]\n",
    "    \n",
    "    for q in questions:\n",
    "        for r in responses:\n",
    "            trainer.train([q, r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310d5a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Behr perform?\n"
     ]
    }
   ],
   "source": [
    "response = consultant_bot.get_response(\"How did Afundi perform?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6252be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can answer faculty evaluation questions if you ask about a specific instructor.\n"
     ]
    }
   ],
   "source": [
    "response = consultant_bot.get_response(\"evaluation for Afundi?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fc6c6",
   "metadata": {},
   "source": [
    "bet so atleast it knows that afundi is Afundi patrick omuhinda.\n",
    "now we’re ready to make this bot truly smart. Instead of relying on memorized Q&A, we’ll wire it to query the SQLite database live when it detects an instructor’s name. That way, even if the phrasing is new or untrained, the bot can still respond accurately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a44ab",
   "metadata": {},
   "source": [
    "# Lookup wiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cebafb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we gotta create the lookup function\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = str(name).lower().strip()\n",
    "    name = re.sub(r\"[^a-z ]\", \"\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name\n",
    "\n",
    "def lookup_instructor_evaluation(user_input):\n",
    "    # Normalize input\n",
    "    normalized_input = normalize_name(user_input)\n",
    "\n",
    "    # Connect to DB\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Load instructor names\n",
    "    cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG'\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Try to match instructor name\n",
    "    for name, score, grade in rows:\n",
    "        if normalize_name(name) in normalized_input:\n",
    "            return f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\"\n",
    "\n",
    "    return \"I couldn’t find that instructor in the database. Please check the spelling or try a different name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d79dd4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn’t find that instructor in the database. Please check the spelling or try a different name.\n"
     ]
    }
   ],
   "source": [
    "# now just gotta wrap it ina bot response\n",
    "user_query = \"How did Behr perform?\"\n",
    "response = lookup_instructor_evaluation(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a708b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn’t find that instructor in the database. Please check the spelling or try a different name.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"How did Afundi perform?\"\n",
    "response = lookup_instructor_evaluation(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5292ce2c",
   "metadata": {},
   "source": [
    "ok this is a bit concerning now. But im thinking, a hybrid chatbot logic so the AI can handle both trained responses and dynamic database lookups. This will make it truly intelligent: if ChatterBot doesn’t know the answer, it’ll fall back to querying the SQLite DB live.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d127fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So lets define the function\n",
    "def lookup_instructor_evaluation(user_input):\n",
    "    import sqlite3\n",
    "    import re\n",
    "\n",
    "    def normalize_name(name):\n",
    "        name = str(name).lower().strip()\n",
    "        name = re.sub(r\"[^a-z ]\", \"\", name)\n",
    "        name = re.sub(r\"\\s+\", \" \", name)\n",
    "        return name\n",
    "\n",
    "    normalized_input = normalize_name(user_input)\n",
    "\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG'\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    for name, score, grade in rows:\n",
    "        if normalize_name(name) in normalized_input:\n",
    "            return f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\"\n",
    "\n",
    "    return None  # Return None if no match found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "758d9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then let me combine the two\n",
    "def get_consultant_response(user_query):\n",
    "    # First try ChatterBot\n",
    "    response = consultant_bot.get_response(user_query)\n",
    "    confidence = float(response.confidence)\n",
    "\n",
    "    # If confidence is high, return ChatterBot response\n",
    "    if confidence >= 0.75:\n",
    "        return str(response)\n",
    "\n",
    "    # Otherwise, try dynamic DB lookup\n",
    "    db_response = lookup_instructor_evaluation(user_query)\n",
    "    if db_response:\n",
    "        return db_response\n",
    "\n",
    "    # Fallback if nothing matches\n",
    "    return \"I couldn’t find that instructor in the database. Please check the spelling or try a different name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866a8a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Behr perform?\n"
     ]
    }
   ],
   "source": [
    "# Now lets test it out\n",
    "user_query = \"How did Akosa perform?\"\n",
    "response = get_consultant_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f86c8",
   "metadata": {},
   "source": [
    "ok so ran the functions and combined and that worked. But im only getting these two responses 'I couldn’t find that instructor in the database. Please check the spelling or try a different name.' and 'How did Afundi perform?'. Also ive noticed if I change the name to like Akosa, it loops thru the responses then it adds in Akosa instead of Afundi after a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "397f4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consultant_response(user_query):\n",
    "    response = consultant_bot.get_response(user_query)\n",
    "    confidence = float(response.confidence)\n",
    "\n",
    "    if confidence >= 0.75:\n",
    "        return str(response)\n",
    "\n",
    "    db_response = lookup_instructor_evaluation(user_query)\n",
    "    if db_response:\n",
    "        return db_response\n",
    "\n",
    "    return \"I couldn’t find that instructor in the database. Please check the spelling or try a different name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "238350a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so im thinking that i can use partial matching to get the rows that matched \n",
    "def lookup_instructor_evaluation(user_input):\n",
    "    import sqlite3\n",
    "    import re\n",
    "\n",
    "    def normalize_name(name):\n",
    "        name = str(name).lower().strip()\n",
    "        name = re.sub(r\"[^a-z ]\", \"\", name)\n",
    "        name = re.sub(r\"\\s+\", \" \", name)\n",
    "        return name\n",
    "\n",
    "    normalized_input = normalize_name(user_input)\n",
    "    input_tokens = set(normalized_input.split())\n",
    "\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG'\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    for name, score, grade in rows:\n",
    "        normalized_name = normalize_name(name)\n",
    "        name_tokens = set(normalized_name.split())\n",
    "\n",
    "        # Match if there's any token overlap\n",
    "        if input_tokens & name_tokens:\n",
    "            return f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc6c1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Behr perform?\n"
     ]
    }
   ],
   "source": [
    "# now lets test it again\n",
    "user_query = \"How did Akosa perform?\"\n",
    "response = get_consultant_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36069f",
   "metadata": {},
   "source": [
    "ayt that looping is an issue so lets try some fuzzy matching like we did in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc730e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training corpus: 19it [00:02,  6.39it/s]\n",
      "Training corpus: 1it [00:00, 26.14it/s]\n",
      "Training corpus: 1it [00:00,  8.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "\n",
    "# Create a new trainer for the chatbot\n",
    "trainer = ChatterBotCorpusTrainer(consultant_bot)\n",
    "\n",
    "# Train based on the english corpus\n",
    "trainer.train(\"chatterbot.corpus.english\")\n",
    "\n",
    "# Train based on english greetings corpus\n",
    "trainer.train(\"chatterbot.corpus.english.greetings\")\n",
    "\n",
    "# Train based on the english conversations corpus\n",
    "trainer.train(\"chatterbot.corpus.english.conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eba069",
   "metadata": {},
   "source": [
    "this code chunk above was just to make sure teh bot understands english and basic greetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c5e1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So id decided to update the fuzzy matching logic and to see whats going on with it\n",
    "from rapidfuzz import fuzz\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = str(name).lower().strip()\n",
    "    name = re.sub(r\"[^a-z ]\", \"\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name\n",
    "\n",
    "def lookup_instructor_evaluation(user_input, threshold=70):\n",
    "    normalized_input = normalize_name(user_input)\n",
    "\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG'\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for name, score, grade in rows:\n",
    "        normalized_name = normalize_name(name)\n",
    "        similarity = fuzz.partial_ratio(normalized_input, normalized_name)\n",
    "\n",
    "        if similarity > best_score:\n",
    "            best_score = similarity\n",
    "            best_match = (name, score, grade)\n",
    "\n",
    "    if best_match and best_score >= threshold:\n",
    "        name, score, grade = best_match\n",
    "        return f\"Based on evaluations, {name} received a grade of {grade} with a mean score of {score}.\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8553bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consultant_response(user_query):\n",
    "    response = consultant_bot.get_response(user_query)\n",
    "    confidence = float(response.confidence)\n",
    "\n",
    "    if confidence >= 0.75:\n",
    "        return str(response)\n",
    "\n",
    "    db_response = lookup_instructor_evaluation(user_query)\n",
    "    if db_response:\n",
    "        return db_response\n",
    "\n",
    "    return \"I couldn’t find that instructor in the database. Please check the spelling or try a different name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9caef135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn’t find that instructor in the database. Please check the spelling or try a different name.\n"
     ]
    }
   ],
   "source": [
    "# now lets test it again\n",
    "user_query = \"can you give me a type of question that i can ask you\"\n",
    "response = get_consultant_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01eb37",
   "metadata": {},
   "source": [
    "ok so it can handle basic conversations but i want more. I need it to understand intent. So lets build one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dde0bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_intent(user_input):\n",
    "    import re\n",
    "\n",
    "    input_lower = user_input.lower()\n",
    "\n",
    "    # Instructor lookup\n",
    "    if \"how did\" in input_lower or \"tell me about\" in input_lower:\n",
    "        return {\"intent\": \"lookup\", \"name\": user_input}\n",
    "\n",
    "    # Score threshold\n",
    "    match_score = re.search(r\"score[s]? above (\\d+(\\.\\d+)?)\", input_lower)\n",
    "    if match_score:\n",
    "        return {\"intent\": \"score_filter\", \"threshold\": float(match_score.group(1))}\n",
    "\n",
    "    # Grade filter\n",
    "    match_grade = re.search(r\"grade[s]? (of )?([abc])\", input_lower)\n",
    "    if match_grade:\n",
    "        return {\"intent\": \"grade_filter\", \"grade\": match_grade.group(2).upper()}\n",
    "\n",
    "    # Top performers\n",
    "    match_top = re.search(r\"top (\\d+)\", input_lower)\n",
    "    if match_top:\n",
    "        return {\"intent\": \"top_ranked\", \"count\": int(match_top.group(1))}\n",
    "\n",
    "    # Negative feedback\n",
    "    if \"negative feedback\" in input_lower or \"bad comments\" in input_lower:\n",
    "        return {\"intent\": \"negative_feedback\"}\n",
    "\n",
    "    # Program filter\n",
    "    match_program = re.search(r\"(undergraduate|doctoral|graduate)\", input_lower)\n",
    "    if match_program:\n",
    "        return {\"intent\": \"program_filter\", \"program\": match_program.group(1).upper()}\n",
    "\n",
    "    return {\"intent\": \"unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb05732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Afundi perform?\n"
     ]
    }
   ],
   "source": [
    "# now lets test it again\n",
    "user_query = \"How did Afundi Patrick perform\"\n",
    "response = get_consultant_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3ab2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ayt let me add in a score threshold for the data\n",
    "def parse_intent(user_input):\n",
    "    import re\n",
    "    input_lower = user_input.lower()\n",
    "\n",
    "    # Score threshold intent\n",
    "    match_score = re.search(r\"score[s]? above (\\d+(\\.\\d+)?)\", input_lower)\n",
    "    if match_score:\n",
    "        return {\"intent\": \"score_filter\", \"threshold\": float(match_score.group(1))}\n",
    "\n",
    "    # Top performers intent\n",
    "    match_top = re.search(r\"top (\\d+)\", input_lower)\n",
    "    if match_top:\n",
    "        return {\"intent\": \"top_ranked\", \"count\": int(match_top.group(1))}\n",
    "\n",
    "    # Instructor lookup (fallback)\n",
    "    if \"how did\" in input_lower or \"tell me about\" in input_lower or \"evaluation for\" in input_lower:\n",
    "        return {\"intent\": \"lookup\", \"name\": user_input}\n",
    "\n",
    "    return {\"intent\": \"unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4305f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next i need some handlers\n",
    "import sqlite3\n",
    "\n",
    "def handle_score_filter(threshold):\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG' AND mean_score > ?\", (threshold,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    if rows:\n",
    "        response = f\"Instructors with scores above {threshold}:\\n\"\n",
    "        for name, score, grade in rows:\n",
    "            response += f\"- {name}: {score} ({grade})\\n\"\n",
    "        return response.strip()\n",
    "    return f\"No instructors scored above {threshold}.\"\n",
    "\n",
    "def handle_top_ranked(count):\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT full_name, mean_score, letter_grade FROM faculty_evaluations WHERE program='UNDG' ORDER BY mean_score DESC LIMIT ?\", (count,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    if rows:\n",
    "        response = f\"Top {count} performers:\\n\"\n",
    "        for name, score, grade in rows:\n",
    "            response += f\"- {name}: {score} ({grade})\\n\"\n",
    "        return response.strip()\n",
    "    return f\"No data available for top {count} performers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c194e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then i gotta combine everything\n",
    "def get_consultant_response(user_query):\n",
    "    # First parse intent\n",
    "    intent = parse_intent(user_query)\n",
    "\n",
    "    if intent[\"intent\"] == \"score_filter\":\n",
    "        return handle_score_filter(intent[\"threshold\"])\n",
    "\n",
    "    elif intent[\"intent\"] == \"top_ranked\":\n",
    "        return handle_top_ranked(intent[\"count\"])\n",
    "\n",
    "    elif intent[\"intent\"] == \"lookup\":\n",
    "        db_response = lookup_instructor_evaluation(user_query)\n",
    "        if db_response:\n",
    "            return db_response\n",
    "        return \"I couldn’t find that instructor in the database.\"\n",
    "\n",
    "    else:\n",
    "        # Fall back to ChatterBot\n",
    "        response = consultant_bot.get_response(user_query)\n",
    "        return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ade95224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the evaluation for Afundi, Patrick Omuhinda?\n",
      "A lot of things, like all the other digits other than 0 and 1.\n"
     ]
    }
   ],
   "source": [
    "# Now we test it \n",
    "# now lets test it again\n",
    "user_query = \"Who scored above 4.5?\"\n",
    "response = get_consultant_response(user_query)\n",
    "print(response)\n",
    "\n",
    "# Now we test it \n",
    "# now lets test it again\n",
    "user_query = \"what annoys you?\"\n",
    "response = get_consultant_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "833a6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_intent(user_input):\n",
    "    text = user_input.lower().strip()\n",
    "\n",
    "    # Top N performers (supports \"top 5\", \"top five\")\n",
    "    m_top = re.search(r\"top\\s+(\\d+|one|two|three|four|five|six|seven|eight|nine|ten)\", text)\n",
    "    if m_top:\n",
    "        word = m_top.group(1)\n",
    "        word_to_num = {\n",
    "            \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "            \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10\n",
    "        }\n",
    "        count = int(word) if word.isdigit() else word_to_num.get(word, 5)\n",
    "        return {\"intent\": \"top_ranked\", \"count\": count}\n",
    "\n",
    "    # Score filters: above/below/exact\n",
    "    m_above = re.search(r\"(score|scores|mean score)\\s*(above|over|greater than)\\s*(\\d+(\\.\\d+)?)\", text)\n",
    "    if m_above:\n",
    "        return {\"intent\": \"score_filter\", \"op\": \">\", \"threshold\": float(m_above.group(3))}\n",
    "\n",
    "    m_below = re.search(r\"(score|scores|mean score)\\s*(below|under|less than)\\s*(\\d+(\\.\\d+)?)\", text)\n",
    "    if m_below:\n",
    "        return {\"intent\": \"score_filter\", \"op\": \"<\", \"threshold\": float(m_below.group(3))}\n",
    "\n",
    "    m_equal = re.search(r\"(score|scores|mean score)\\s*(equal|equals|=|is)\\s*(\\d+(\\.\\d+)?)\", text)\n",
    "    if m_equal or re.search(r\"who scored\\s+(\\d+(\\.\\d+)?)\", text):\n",
    "        val = float(m_equal.group(3)) if m_equal else float(re.search(r\"who scored\\s+(\\d+(\\.\\d+)?)\", text).group(1))\n",
    "        return {\"intent\": \"score_filter\", \"op\": \"=\", \"threshold\": val}\n",
    "\n",
    "    # Grade filters: \"who got an A\", \"grade B\"\n",
    "    m_grade = re.search(r\"(grade|got a|received a)\\s*([abc])\\b\", text)\n",
    "    if m_grade:\n",
    "        return {\"intent\": \"grade_filter\", \"grade\": m_grade.group(2).upper()}\n",
    "\n",
    "    # Instructor lookup\n",
    "    if any(kw in text for kw in [\"how did\", \"tell me about\", \"evaluation for\", \"performance of\", \"results for\"]):\n",
    "        return {\"intent\": \"lookup\", \"name\": user_input}\n",
    "\n",
    "    return {\"intent\": \"unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8849a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consultant_response(user_query):\n",
    "    intent = parse_intent(user_query)\n",
    "\n",
    "    # Intent-first routing\n",
    "    if intent[\"intent\"] == \"top_ranked\":\n",
    "        return handle_top_ranked(intent[\"count\"])\n",
    "\n",
    "    if intent[\"intent\"] == \"score_filter\":\n",
    "        return handle_score_filter(intent[\"op\"], intent[\"threshold\"])\n",
    "\n",
    "    if intent[\"intent\"] == \"grade_filter\":\n",
    "        return handle_grade_filter(intent[\"grade\"])\n",
    "\n",
    "    if intent[\"intent\"] == \"lookup\":\n",
    "        db_resp = lookup_instructor_evaluation(user_query)\n",
    "        if db_resp:\n",
    "            return db_resp\n",
    "        return \"I couldn’t find that instructor in the database.\"\n",
    "\n",
    "    # Last resort: ChatterBot\n",
    "    response = consultant_bot.get_response(user_query)\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac19bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 0\n",
      "Programs: []\n",
      "Sample: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def debug_db_overview():\n",
    "    conn = sqlite3.connect(\"faculty_evaluations.sqlite\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT COUNT(*) FROM faculty_evaluations\")\n",
    "    total = c.fetchone()[0]\n",
    "\n",
    "    c.execute(\"SELECT DISTINCT program FROM faculty_evaluations ORDER BY program\")\n",
    "    programs = [row[0] for row in c.fetchall()]\n",
    "\n",
    "    c.execute(\"SELECT full_name, mean_score, letter_grade, program FROM faculty_evaluations LIMIT 5\")\n",
    "    sample = c.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return {\"total_rows\": total, \"programs\": programs, \"sample\": sample}\n",
    "\n",
    "info = debug_db_overview()\n",
    "print(\"Total rows:\", info[\"total_rows\"])\n",
    "print(\"Programs:\", info[\"programs\"])\n",
    "print(\"Sample:\", info[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911891ff",
   "metadata": {},
   "source": [
    "this is it, the bane of my existence, there was nothing to be found. Thats why i was gettinf nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7114d971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is 05:19 PM\n",
      "The current time is 05:19 PM\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "\n",
    "\n",
    "bot = ChatBot(\n",
    "    'Math & Time Bot',\n",
    "    logic_adapters=[\n",
    "        'chatterbot.logic.MathematicalEvaluation',\n",
    "        'chatterbot.logic.TimeLogicAdapter'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print an example of getting one math based response\n",
    "response = bot.get_response('Who is john f. kennedy')\n",
    "print(response)\n",
    "\n",
    "\n",
    "response = bot.get_response('What is baseball')\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7acd4d6",
   "metadata": {},
   "source": [
    "ok so I decided to go back to my folder and check on the db. And I found 5 dbs are present . So I went thru each. And this is what I found\n",
    "consultant db has three tables statement: text search_text conversation created_at in_response_to search_in_response_to persona id\n",
    "tag : name id\n",
    "tag associations: tag_id statement_id\n",
    "from what I can gather it seems to be a knowledge base for the defuatl db that can answer simple questions such as what is baseball or soccer. and when I ased our consultant Ai what is baseball it told me 'a game with tall players' and another question I gave it was tell me a joke, and it told me 'Did you hear the one about the mountain goats in the andes? It was \"ba a a a a a d'\n",
    "so it seems we were connecting to this database instead of the one that we made\n",
    "I still ran another question from the db that asked what annoys you and I got 'A lot of things, like all the other digits other than 0 and 1.'\n",
    "so that means our bot was connected to a db and functions as should, but It was connected to the wrong db. But this is atleast good cause the plane was to move from a general Chat bot to\n",
    "db .sqlite4 is where the past questions are stored it has these 3 tables statement: each row is: text search_text conversation created_at in_response_to search_in_response_to persona id\n",
    "tag: name id\n",
    "tag_association: tag_id statement_id\n",
    "faculty_evaluation.db is the db that we made it has the tables that we made for it Courses Deans Evaluations Faculty FeedbackCorpus Sections TeachingAssingments sqlite_sequence: name seq\n",
    "faculty_evaluation.sqlite is entirely empty with no tables in it either that's why its 0kbs\n",
    "faculty_evaluations.sqlite has this table faculty_evalations: full_name mean_score letter_grade program So it seems we were connecting to the worng db. So what im thinking now is that w'll scrap everything that we did before and start afresh with this new knowledge. Cause from what weve learnt is that we did correctly build a generic chatbot and it operated as intedended, we were just asking it the wrong questions and expecting it to answer what it doesn't know. So im going to create a new notebook and we''ll start a fresh\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
